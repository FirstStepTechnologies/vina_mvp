{
  "Clinical Researcher": {
    "profession": "Clinical Researcher",
    "questions": [
      {
        "id": "q1",
        "text": "When an LLM generates a response, what is it fundamentally doing?",
        "options": [
          {
            "text": "It is retrieving the most accurate fact from a verified medical database.",
            "is_correct": false
          },
          {
            "text": "It is predicting the next statistically likely token based on the patterns it learned during training.",
            "is_correct": true
          },
          {
            "text": "It is searching the live internet to copy and paste the best matching paragraph.",
            "is_correct": false
          },
          {
            "text": "It is reasoning with human-like consciousness to determine the truth.",
            "is_correct": false
          }
        ],
        "correctAnswer": "B",
        "associatedLesson": "l01_what_llms_are",
        "difficultyLevel": 1,
        "explanation": "LLMs function as probabilistic engines that predict the next chunk of text (token) based on training patterns, rather than querying a database of verified facts.",
        "rationale": "Tests the most fundamental misconception (search engine vs. text predictor) which is critical for Stage 1 placement.",
        "isProfessionSpecific": false,
        "conceptTested": "probabilistic_prediction"
      },
      {
        "id": "q2",
        "text": "You are generating a summary of a document and you need the output to be as consistent and deterministic as possible. How should you adjust the 'Temperature' setting?",
        "options": [
          {
            "text": "Set it to 0 to minimize randomness and prioritize the most likely tokens.",
            "is_correct": true
          },
          {
            "text": "Set it to 0.5 to balance creativity with accuracy.",
            "is_correct": false
          },
          {
            "text": "Set it to 1.0 to ensure the model tries harder to find the correct answer.",
            "is_correct": false
          },
          {
            "text": "Temperature does not affect consistency, only speed.",
            "is_correct": false
          }
        ],
        "correctAnswer": "A",
        "associatedLesson": "l03_why_outputs_vary",
        "difficultyLevel": 2,
        "explanation": "Lower temperature settings (close to 0) force the model to choose the highest probability tokens, resulting in more consistent and reproducible outputs.",
        "rationale": "Tests a deeper Stage 1 mechanical concept (parameters) that dictates how the model behaves.",
        "isProfessionSpecific": false,
        "conceptTested": "temperature_parameter"
      },
      {
        "id": "q3",
        "text": "Which of the following describes a 'hallucination' in the context of Large Language Models?",
        "options": [
          {
            "text": "When the model refuses to answer a question due to safety filters.",
            "is_correct": false
          },
          {
            "text": "When the model generates a response that sounds plausible and authoritative but is factually incorrect.",
            "is_correct": true
          },
          {
            "text": "When the model crashes or times out because the input text was too long.",
            "is_correct": false
          },
          {
            "text": "When the model plagiarizes text directly from a copyrighted source.",
            "is_correct": false
          }
        ],
        "correctAnswer": "B",
        "associatedLesson": "l05_hallucinations",
        "difficultyLevel": 3,
        "explanation": "Hallucinations occur when an LLM confidently generates false information because it prioritizes linguistic fluency and pattern matching over factual accuracy.",
        "rationale": "Tests a critical Stage 2 risk concept that is vital for determining if the learner understands system limitations.",
        "isProfessionSpecific": false,
        "conceptTested": "hallucinations"
      },
      {
        "id": "q4",
        "text": "You are a Clinical Researcher stripping PII (Personally Identifiable Information) from patient narratives. You paste a raw patient note into a public, free LLM interface (like standard ChatGPT) to ask it to anonymize the text. Why is this considered a 'Poor Fit' workflow?",
        "options": [
          {
            "text": "Because the LLM will likely hallucinate new patient symptoms.",
            "is_correct": false
          },
          {
            "text": "Because LLMs are not capable of understanding medical terminology.",
            "is_correct": false
          },
          {
            "text": "Because sending PII to a public model provider violates data privacy and HIPAA compliance standards.",
            "is_correct": true
          },
          {
            "text": "Because the context window is too small to handle a single patient note.",
            "is_correct": false
          }
        ],
        "correctAnswer": "C",
        "associatedLesson": "l07_safe_use_practices",
        "difficultyLevel": 4,
        "explanation": "Public model inputs are often used for training or logged by the provider, making them unsuitable for handling sensitive protected health information (PHI/PII).",
        "rationale": "Tests Stage 2 application concepts within a specific professional scenario involving data privacy and workflow safety.",
        "isProfessionSpecific": true,
        "conceptTested": "data_privacy_risk"
      },
      {
        "id": "q5",
        "text": "You are designing a prompt to extract adverse events from a clinical trial report. You try once, but the model misses several events. You decide to provide the model with three examples of 'Input Report -> Extracted Adverse Events' before asking it to extract events from your new report. What prompting strategy are you using?",
        "options": [
          {
            "text": "Zero-Shot Prompting",
            "is_correct": false
          },
          {
            "text": "Chain-of-Thought Prompting",
            "is_correct": false
          },
          {
            "text": "Few-Shot Prompting",
            "is_correct": true
          },
          {
            "text": "Retrieval Augmented Generation (RAG)",
            "is_correct": false
          }
        ],
        "correctAnswer": "C",
        "associatedLesson": "l15_few_shot_prompting",
        "difficultyLevel": 5,
        "explanation": "Few-Shot Prompting involves giving the model a few clear examples of the task (input and desired output) to guide its pattern recognition for the actual request.",
        "rationale": "Tests advanced Stage 3 prompting optimization techniques applied to a specific clinical research task.",
        "isProfessionSpecific": true,
        "conceptTested": "few_shot_prompting"
      }
    ]
  },
  "HR Manager": {
    "profession": "HR Manager",
    "questions": [
      {
        "id": "q1",
        "text": "When you input a 1,000-word employee handbook section into an LLM and ask for a summary, how does the model 'see' that text?",
        "options": [
          {
            "text": "It reads the text word-by-word, exactly like a human reads a book.",
            "is_correct": false
          },
          {
            "text": "It breaks the text down into chunks called 'tokens,' which are roughly 3/4 of a word each.",
            "is_correct": true
          },
          {
            "text": "It scans the text for keywords and ignores the connecting grammar.",
            "is_correct": false
          },
          {
            "text": "It converts the text into a single image and processes it visually.",
            "is_correct": false
          }
        ],
        "correctAnswer": "B",
        "associatedLesson": "l02_tokens_context",
        "difficultyLevel": 1,
        "explanation": "LLMs process language in units called tokens (parts of words) rather than whole words or sentences, which is essential for understanding cost and length limits.",
        "rationale": "Tests basic understanding of the fundamental unit of measurement (tokens) in LLMs.",
        "isProfessionSpecific": false,
        "conceptTested": "tokens"
      },
      {
        "id": "q2",
        "text": "You ask an LLM to write a generic welcome email for new hires. You run the prompt three times, and every time the output is slightly different. Why does this happen?",
        "options": [
          {
            "text": "The model is learning from your previous prompts in real-time and adjusting its style.",
            "is_correct": false
          },
          {
            "text": "The model is confused by the prompt and is trying to guess what you want.",
            "is_correct": false
          },
          {
            "text": "The model uses probabilistic prediction to choose the next token, meaning there is an element of randomness in its selection.",
            "is_correct": true
          },
          {
            "text": "The model has access to different databases each time you click 'generate'.",
            "is_correct": false
          }
        ],
        "correctAnswer": "C",
        "associatedLesson": "l03_why_outputs_vary",
        "difficultyLevel": 2,
        "explanation": "LLMs aren't static databases; they calculate the probability of the next word appearing. Unless the 'temperature' is set to zero, there is always a chance it will pick a different valid word.",
        "rationale": "Tests understanding of the probabilistic nature of LLMs (Stage 1 concept) at a slightly deeper level than simple definition.",
        "isProfessionSpecific": false,
        "conceptTested": "probabilistic_outputs"
      },
      {
        "id": "q3",
        "text": "Which of the following tasks poses the highest risk of 'hallucination' if you rely solely on an LLM without checking the facts?",
        "options": [
          {
            "text": "Brainstorming five creative themes for the company holiday party.",
            "is_correct": false
          },
          {
            "text": "Rewriting a messy paragraph into a professional tone.",
            "is_correct": false
          },
          {
            "text": "Citing specific labor laws and recent court cases regarding overtime pay in California.",
            "is_correct": true
          },
          {
            "text": "Translating a brief email from English to Spanish.",
            "is_correct": false
          }
        ],
        "correctAnswer": "C",
        "associatedLesson": "l05_hallucinations",
        "difficultyLevel": 3,
        "explanation": "LLMs are excellent at language tasks (rewriting, brainstorming) but struggle with specific factual retrieval like citations, often inventing plausible-sounding but non-existent cases.",
        "rationale": "Tests application of Stage 2 risk concepts (hallucination) by distinguishing between high-risk and low-risk use cases.",
        "isProfessionSpecific": false,
        "conceptTested": "hallucinations"
      },
      {
        "id": "q4",
        "text": "You want to use an LLM to help screen resumes. To ensure 'Good Fit' and avoid ethical pitfalls, what is the most critical first step before feeding resumes into the model?",
        "options": [
          {
            "text": "Remove all Personally Identifiable Information (PII) like names and addresses to protect privacy and reduce bias.",
            "is_correct": true
          },
          {
            "text": "Tell the model to only look for candidates who attended Ivy League schools to ensure high quality.",
            "is_correct": false
          },
          {
            "text": "Ask the model to rank the candidates from 1 to 10 based on their 'leadership vibes.'",
            "is_correct": false
          },
          {
            "text": "Upload the resumes immediately to see if the model can guess the candidate's age.",
            "is_correct": false
          }
        ],
        "correctAnswer": "A",
        "associatedLesson": "l07_safe_use_practices",
        "difficultyLevel": 4,
        "explanation": "Protecting candidate data is a primary ethical and legal obligation. Furthermore, anonymization helps mitigate (though not eliminate) potential demographic biases in the model.",
        "rationale": "Tests Stage 2 concepts (Safe Use/Bias) applied directly to a sensitive HR workflow.",
        "isProfessionSpecific": true,
        "conceptTested": "data_privacy_and_bias"
      },
      {
        "id": "q5",
        "text": "You are creating a prompt to help managers write performance reviews. To get the most consistent and high-quality results from the LLM, which 'Few-Shot' technique should you use?",
        "options": [
          {
            "text": "Write: 'You are a helpful HR assistant. Write a performance review.'",
            "is_correct": false
          },
          {
            "text": "Provide three examples of 'Input: Raw Manager Notes' paired with 'Output: Ideally Written Review' before asking it to write the new one.",
            "is_correct": true
          },
          {
            "text": "Upload the entire employee handbook and ask the model to memorize it before writing the review.",
            "is_correct": false
          },
          {
            "text": "Tell the model: 'Do not be biased, do not be rude, do not be too long, and make sure it sounds professional.'",
            "is_correct": false
          }
        ],
        "correctAnswer": "B",
        "associatedLesson": "l15_few_shot_prompting",
        "difficultyLevel": 5,
        "explanation": "Few-shot prompting involves giving the model clear examples of what you want (input) and what the result should look like (output) to guide its pattern recognition.",
        "rationale": "Tests advanced Stage 3 prompt engineering skill (Few-Shot Prompting) in a specific HR context.",
        "isProfessionSpecific": true,
        "conceptTested": "few_shot_prompting"
      }
    ]
  },
  "Project Manager": {
    "profession": "Project Manager",
    "questions": [
      {
        "id": "q1",
        "text": "When you input text into an LLM like ChatGPT, the system breaks your words down into smaller chunks called 'tokens' before processing them. Roughly how does the token count compare to the word count in standard English text?",
        "options": [
          {
            "text": "100 words equals roughly 10 tokens.",
            "is_correct": false
          },
          {
            "text": "100 words equals roughly 75 tokens.",
            "is_correct": false
          },
          {
            "text": "100 words equals roughly 130 tokens.",
            "is_correct": true
          },
          {
            "text": "100 words equals exactly 100 tokens.",
            "is_correct": false
          }
        ],
        "correctAnswer": "C",
        "associatedLesson": "l02_tokens_context",
        "difficultyLevel": 1,
        "explanation": "Tokens are chunks of characters, and a general rule of thumb is that 1 token is approximately 0.75 words (or 1000 tokens is about 750 words). This means the token count is usually higher than the word count.",
        "rationale": "Tests basic understanding of the fundamental unit of measurement (tokens) essential for understanding cost and limits.",
        "isProfessionSpecific": false,
        "conceptTested": "tokens_vs_words"
      },
      {
        "id": "q2",
        "text": "You are generating a project summary using an LLM, but every time you run the same prompt, the output is slightly different. Which technical parameter is most likely responsible for controlling this randomness?",
        "options": [
          {
            "text": "The Temperature setting",
            "is_correct": true
          },
          {
            "text": "The Context Window size",
            "is_correct": false
          },
          {
            "text": "The Training Data cutoff",
            "is_correct": false
          },
          {
            "text": "The API Latency",
            "is_correct": false
          }
        ],
        "correctAnswer": "A",
        "associatedLesson": "l03_why_outputs_vary",
        "difficultyLevel": 2,
        "explanation": "Temperature is a parameter (usually between 0 and 1) that controls how much randomness the model introduces when predicting the next token. A lower temperature yields more deterministic results.",
        "rationale": "Tests deeper mechanical knowledge of why LLMs behave probabilistically rather than deterministically.",
        "isProfessionSpecific": false,
        "conceptTested": "temperature_randomness"
      },
      {
        "id": "q3",
        "text": "A team member suggests using a public LLM to draft a response to a sensitive client email containing proprietary roadmap details. Why is this considered a 'poor fit' use case regarding data safety?",
        "options": [
          {
            "text": "LLMs cannot understand the tone required for client emails.",
            "is_correct": false
          },
          {
            "text": "Public LLMs usually hallucinate when discussing dates.",
            "is_correct": false
          },
          {
            "text": "The input data may be used to train future versions of the model, exposing secrets.",
            "is_correct": true
          },
          {
            "text": "The context window will definitely be too small for the email thread.",
            "is_correct": false
          }
        ],
        "correctAnswer": "C",
        "associatedLesson": "l07_safe_use_practices",
        "difficultyLevel": 3,
        "explanation": "Unless specific enterprise privacy settings are enabled, data entered into public LLM interfaces can potentially be stored and used for model training, creating a data leakage risk.",
        "rationale": "Tests application of risk concepts regarding data privacy, a critical Stage 2 skill.",
        "isProfessionSpecific": false,
        "conceptTested": "data_privacy_risk"
      },
      {
        "id": "q4",
        "text": "As a PM, you want to use an LLM to identify risks in a new requirements document. You paste the requirements in and ask: 'What are the risks?'. The LLM returns a generic list of risks that don't apply to your specific project. What is the most likely cause of this 'Hallucination' or irrelevance?",
        "options": [
          {
            "text": "The model is biased against your specific industry.",
            "is_correct": false
          },
          {
            "text": "The model lacks the specific context of your project's constraints and history.",
            "is_correct": true
          },
          {
            "text": "The requirements document was too short to be tokenized.",
            "is_correct": false
          },
          {
            "text": "LLMs are inherently incapable of risk analysis tasks.",
            "is_correct": false
          }
        ],
        "correctAnswer": "B",
        "associatedLesson": "l05_hallucinations",
        "difficultyLevel": 4,
        "explanation": "LLMs predict text based on patterns, not truth. If you fail to provide the necessary ground-truth context (constraints, history, tech stack), the model will 'hallucinate' plausible but factually incorrect or irrelevant details to fill the gap.",
        "rationale": "Tests Stage 2 application concepts within a specific PM job scenario (risk analysis).",
        "isProfessionSpecific": true,
        "conceptTested": "contextual_hallucination"
      },
      {
        "id": "q5",
        "text": "You are designing a prompt to have an LLM automatically convert messy meeting notes into Jira tickets. You want to ensure the output format (JSON) is consistent every single time. Which technique should you apply to your prompt to best achieve this?",
        "options": [
          {
            "text": "Ask the model to 'be creative' with the ticket descriptions.",
            "is_correct": false
          },
          {
            "text": "Few-Shot Prompting (providing 3 examples of messy notes mapped to perfect JSON).",
            "is_correct": true
          },
          {
            "text": "Repeat the instruction 'Use JSON' ten times at the end of the prompt.",
            "is_correct": false
          },
          {
            "text": "Increase the temperature setting to 0.9.",
            "is_correct": false
          }
        ],
        "correctAnswer": "B",
        "associatedLesson": "l15_few_shot_prompting",
        "difficultyLevel": 5,
        "explanation": "Few-Shot Prompting involves giving the model examples of input-output pairs. This is the most effective way to constrain the model's structure and style to get reliable, structured data like JSON.",
        "rationale": "Tests advanced Stage 3 optimization techniques (Few-Shot) applied to a complex PM workflow.",
        "isProfessionSpecific": true,
        "conceptTested": "few_shot_prompting"
      }
    ]
  },
  "Marketing Manager": {
    "profession": "Marketing Manager",
    "questions": [
      {
        "id": "q1",
        "text": "When you input a paragraph of text into an LLM like ChatGPT, how does the model actually 'read' and process that information?",
        "options": [
          {
            "text": "It understands the sentences grammatically, breaking them down into subjects, verbs, and objects like a human linguist.",
            "is_correct": false
          },
          {
            "text": "It converts the text into 'tokens'\u2014chunks of characters roughly equal to 3/4 of a word\u2014and processes them as numerical sequences.",
            "is_correct": true
          },
          {
            "text": "It scans the text for keywords and searches its database for pre-written answers that match those topics.",
            "is_correct": false
          },
          {
            "text": "It processes the text strictly letter-by-letter to ensure zero spelling errors in the output.",
            "is_correct": false
          }
        ],
        "correctAnswer": "B",
        "associatedLesson": "l02_tokens_context",
        "difficultyLevel": 1,
        "explanation": "LLMs do not read words or understand grammar like humans; they break text into 'tokens' (numerical representations of character chunks) to predict patterns.",
        "rationale": "Tests the fundamental mechanic of how LLMs ingest data, establishing a baseline technical literacy required for cost and context estimation.",
        "isProfessionSpecific": false,
        "conceptTested": "tokens"
      },
      {
        "id": "q2",
        "text": "You ask an AI to write a short email. You run the exact same prompt five times. Why might you get five different versions of the email?",
        "options": [
          {
            "text": "The model is learning from your previous requests in real-time and trying to improve the draft each time.",
            "is_correct": false
          },
          {
            "text": "The model has a 'temperature' setting that introduces a degree of randomness in predicting the next token, leading to variations.",
            "is_correct": true
          },
          {
            "text": "The internet connection speed fluctuates, causing the AI to retrieve different data packets.",
            "is_correct": false
          },
          {
            "text": "The AI is A/B testing different emotional tones to see which one you prefer.",
            "is_correct": false
          }
        ],
        "correctAnswer": "B",
        "associatedLesson": "l03_why_outputs_vary",
        "difficultyLevel": 2,
        "explanation": "LLMs are probabilistic, not deterministic. A parameter called 'temperature' controls how much randomness is allowed when the model selects the next likely word.",
        "rationale": "Tests understanding of probabilistic nature vs. deterministic software, crucial for managing expectations about consistency.",
        "isProfessionSpecific": false,
        "conceptTested": "probabilistic_output"
      },
      {
        "id": "q3",
        "text": "Which of the following scenarios represents the highest risk for 'hallucination' when using a standard Large Language Model?",
        "options": [
          {
            "text": "Summarizing a 500-word article that you pasted directly into the chat window.",
            "is_correct": false
          },
          {
            "text": "Translating a paragraph of text from English to Spanish.",
            "is_correct": false
          },
          {
            "text": "Asking the model to cite specific medical studies and authors from 2023 without providing source material.",
            "is_correct": true
          },
          {
            "text": "Brainstorming ten creative ideas for a summer picnic theme.",
            "is_correct": false
          }
        ],
        "correctAnswer": "C",
        "associatedLesson": "l05_hallucinations",
        "difficultyLevel": 3,
        "explanation": "Hallucinations occur most frequently when asking for specific facts (citations, math, dates) that the model doesn't have in its immediate context window, causing it to confidently invent plausible-sounding details.",
        "rationale": "Tests the ability to identify high-risk use cases, a critical skill for safe application of the technology.",
        "isProfessionSpecific": false,
        "conceptTested": "hallucinations"
      },
      {
        "id": "q4",
        "text": "As a Marketing Manager, you want to use an LLM to analyze customer feedback. You have a spreadsheet with 500 rows of raw comments. Which approach best represents a 'Good Fit' task that maximizes ROI?",
        "options": [
          {
            "text": "Ask the LLM to count exactly how many times the word 'expensive' appears in the sheet to calculate a percentage.",
            "is_correct": false
          },
          {
            "text": "Ask the LLM to classify the sentiment of each comment (Positive, Neutral, Negative) and extract the top 3 recurring themes.",
            "is_correct": true
          },
          {
            "text": "Ask the LLM to verify if the customers' email addresses in the spreadsheet are valid and active.",
            "is_correct": false
          },
          {
            "text": "Ask the LLM to look up the LinkedIn profiles of every customer to enrich your CRM data.",
            "is_correct": false
          }
        ],
        "correctAnswer": "B",
        "associatedLesson": "l09_good_vs_poor_fit",
        "difficultyLevel": 4,
        "explanation": "LLMs excel at qualitative tasks like sentiment analysis, summarization, and pattern recognition (extraction). They are poor at precise math (counting) or interacting with live external databases without tools.",
        "rationale": "Tests the ability to distinguish between tasks LLMs are naturally good at (qualitative analysis) versus tasks that require traditional software (math/validation).",
        "isProfessionSpecific": true,
        "conceptTested": "task_suitability"
      },
      {
        "id": "q5",
        "text": "You need an LLM to generate a press release in your specific brand voice. You have tried asking simply 'Write a press release,' but the tone is generic. What is the most effective advanced prompting strategy to fix this?",
        "options": [
          {
            "text": "Repeat the instruction 'Write a press release' three times in the prompt to emphasize importance.",
            "is_correct": false
          },
          {
            "text": "Tell the model, 'You are a bad writer, please do better,' to trigger its correction mechanism.",
            "is_correct": false
          },
          {
            "text": "Use 'Few-Shot Prompting' by pasting three examples of previous successful press releases into the prompt before asking for the new one.",
            "is_correct": true
          },
          {
            "text": "Lower the temperature setting to 0 to force the model to be more creative.",
            "is_correct": false
          }
        ],
        "correctAnswer": "C",
        "associatedLesson": "l15_few_shot_prompting",
        "difficultyLevel": 5,
        "explanation": "Few-Shot Prompting involves providing examples (shots) of the desired output within the prompt. This guides the model's pattern matching to mimic your specific style and format much better than instructions alone.",
        "rationale": "Tests advanced optimization techniques. The learner understands the basics but needs to know *how* to steer the model effectively using context.",
        "isProfessionSpecific": true,
        "conceptTested": "few_shot_prompting"
      }
    ]
  }
}